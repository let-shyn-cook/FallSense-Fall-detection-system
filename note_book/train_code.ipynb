{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e08fac6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-21T06:15:06.487371Z",
     "iopub.status.busy": "2025-03-21T06:15:06.487135Z",
     "iopub.status.idle": "2025-03-21T06:15:10.810854Z",
     "shell.execute_reply": "2025-03-21T06:15:10.809975Z"
    },
    "papermill": {
     "duration": 4.328362,
     "end_time": "2025-03-21T06:15:10.812741",
     "exception": false,
     "start_time": "2025-03-21T06:15:06.484379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ST-GCN-Pytorch'...\r\n",
      "remote: Enumerating objects: 94, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (28/28), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (27/27), done.\u001b[K\r\n",
      "remote: Total 94 (delta 3), reused 16 (delta 0), pack-reused 66 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (94/94), 113.03 MiB | 47.49 MiB/s, done.\r\n",
      "Resolving deltas: 100% (10/10), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/DuyNguDao/ST-GCN-Pytorch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e578b754",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T06:15:10.818600Z",
     "iopub.status.busy": "2025-03-21T06:15:10.818333Z",
     "iopub.status.idle": "2025-03-21T07:46:21.611964Z",
     "shell.execute_reply": "2025-03-21T07:46:21.610963Z"
    },
    "papermill": {
     "duration": 5472.879423,
     "end_time": "2025-03-21T07:46:23.694879",
     "exception": false,
     "start_time": "2025-03-21T06:15:10.815456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class name: ['Fall Down', 'Lying Down', 'Sit down', 'Sitting', 'Stand up', 'Standing', 'Walking']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Epoch 0:   0%|          | 0/887 [00:00<?, ?batch/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Epoch 0: 100%|██████████| 887/887 [01:42<00:00,  8.68batch/s]\n",
      "Epoch 1: 100%|██████████| 887/887 [01:41<00:00,  8.77batch/s]\n",
      "Epoch 2: 100%|██████████| 887/887 [01:40<00:00,  8.78batch/s]\n",
      "Epoch 3: 100%|██████████| 887/887 [01:40<00:00,  8.79batch/s]\n",
      "Epoch 4: 100%|██████████| 887/887 [01:41<00:00,  8.76batch/s]\n",
      "Epoch 5: 100%|██████████| 887/887 [01:41<00:00,  8.75batch/s]\n",
      "Epoch 6: 100%|██████████| 887/887 [01:41<00:00,  8.76batch/s]\n",
      "Epoch 7: 100%|██████████| 887/887 [01:41<00:00,  8.77batch/s]\n",
      "Epoch 8: 100%|██████████| 887/887 [01:41<00:00,  8.77batch/s]\n",
      "Epoch 9: 100%|██████████| 887/887 [01:41<00:00,  8.78batch/s]\n",
      "Epoch 10: 100%|██████████| 887/887 [01:41<00:00,  8.77batch/s]\n",
      "Epoch 11: 100%|██████████| 887/887 [01:41<00:00,  8.78batch/s]\n",
      "Epoch 12: 100%|██████████| 887/887 [01:41<00:00,  8.78batch/s]\n",
      "Epoch 13: 100%|██████████| 887/887 [01:39<00:00,  8.89batch/s]\n",
      "Epoch 14: 100%|██████████| 887/887 [01:40<00:00,  8.81batch/s]\n",
      "Epoch 15: 100%|██████████| 887/887 [01:40<00:00,  8.80batch/s]\n",
      "Epoch 16: 100%|██████████| 887/887 [01:40<00:00,  8.82batch/s]\n",
      "Epoch 17: 100%|██████████| 887/887 [01:40<00:00,  8.86batch/s]\n",
      "Epoch 18: 100%|██████████| 887/887 [01:40<00:00,  8.83batch/s]\n",
      "Epoch 19: 100%|██████████| 887/887 [01:40<00:00,  8.83batch/s]\n",
      "Epoch 20: 100%|██████████| 887/887 [01:40<00:00,  8.83batch/s]\n",
      "Epoch 21: 100%|██████████| 887/887 [01:40<00:00,  8.85batch/s]\n",
      "Epoch 22: 100%|██████████| 887/887 [01:40<00:00,  8.84batch/s]\n",
      "Epoch 23: 100%|██████████| 887/887 [01:40<00:00,  8.86batch/s]\n",
      "Epoch 24: 100%|██████████| 887/887 [01:40<00:00,  8.82batch/s]\n",
      "Epoch 25: 100%|██████████| 887/887 [01:40<00:00,  8.85batch/s]\n",
      "Epoch 26: 100%|██████████| 887/887 [01:40<00:00,  8.84batch/s]\n",
      "Epoch 27: 100%|██████████| 887/887 [01:40<00:00,  8.83batch/s]\n",
      "Epoch 28: 100%|██████████| 887/887 [01:40<00:00,  8.85batch/s]\n",
      "Epoch 29: 100%|██████████| 887/887 [01:40<00:00,  8.84batch/s]\n",
      "Epoch 30: 100%|██████████| 887/887 [01:40<00:00,  8.85batch/s]\n",
      "Epoch 31: 100%|██████████| 887/887 [01:41<00:00,  8.77batch/s]\n",
      "Epoch 32: 100%|██████████| 887/887 [01:40<00:00,  8.81batch/s]\n",
      "Epoch 33: 100%|██████████| 887/887 [01:40<00:00,  8.81batch/s]\n",
      "Epoch 34: 100%|██████████| 887/887 [01:40<00:00,  8.78batch/s]\n",
      "Epoch 35: 100%|██████████| 887/887 [01:40<00:00,  8.85batch/s]\n",
      "Epoch 36: 100%|██████████| 887/887 [01:40<00:00,  8.85batch/s]\n",
      "Epoch 37: 100%|██████████| 887/887 [01:40<00:00,  8.85batch/s]\n",
      "Epoch 38: 100%|██████████| 887/887 [01:40<00:00,  8.82batch/s]\n",
      "Epoch 39: 100%|██████████| 887/887 [01:40<00:00,  8.87batch/s]\n",
      "Epoch 40: 100%|██████████| 887/887 [01:39<00:00,  8.89batch/s]\n",
      "Epoch 41: 100%|██████████| 887/887 [01:40<00:00,  8.80batch/s]\n",
      "Epoch 42: 100%|██████████| 887/887 [01:40<00:00,  8.82batch/s]\n",
      "Epoch 43: 100%|██████████| 887/887 [01:40<00:00,  8.83batch/s]\n",
      "Epoch 44: 100%|██████████| 887/887 [01:40<00:00,  8.80batch/s]\n",
      "Epoch 45: 100%|██████████| 887/887 [01:40<00:00,  8.84batch/s]\n",
      "Epoch 46: 100%|██████████| 887/887 [01:39<00:00,  8.89batch/s]\n",
      "Epoch 47: 100%|██████████| 887/887 [01:40<00:00,  8.85batch/s]\n",
      "Epoch 48: 100%|██████████| 887/887 [01:39<00:00,  8.88batch/s]\n",
      "Epoch 49: 100%|██████████| 887/887 [01:39<00:00,  8.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete !\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from tqdm import tqdm\n",
    "from torch.utils import data\n",
    "from torch.optim.adadelta import Adadelta\n",
    "import sys\n",
    "sys.path.append('/kaggle/working/ST-GCN-Pytorch')\n",
    "from models.stgcn import *\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from collections import OrderedDict\n",
    "import logging\n",
    "import yaml\n",
    "from dataloader.dataset import processing_data\n",
    "import datetime\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# clear memory cuda\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# Get parameter\n",
    "with open(\"/kaggle/input/yaml-action-pkl/config.yaml\", \"r\") as stream:\n",
    "    try:\n",
    "        config = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(\"Error loading YAML:\", exc)\n",
    "        config = {}\n",
    "\n",
    "# parameter\n",
    "input_dataset_train = config.get('dataset-path-train', '')\n",
    "input_dataset_test = config.get('dataset-path-test', '')\n",
    "epochs = config.get('epochs', 50)\n",
    "batch_size = config.get('batch-size', 32)\n",
    "input_size = config.get('img-size', 224)\n",
    "num_frame = config.get('num-frame', 15)\n",
    "path_save_model = config.get('project', 'saved_models')\n",
    "classes_name = config.get('classes', ['Fall Down', 'Lying Down', 'Sit down', 'Sitting', 'Stand up', 'Standing', 'Walking'])\n",
    "\n",
    "print(\"Class name:\", classes_name)\n",
    "\n",
    "features, labels = [], []\n",
    "# Load dataset train\n",
    "with open(input_dataset_train, 'rb') as f:\n",
    "    fts, lbs = pickle.load(f)\n",
    "    features.append(fts)\n",
    "    labels.append(lbs)\n",
    "del fts, lbs\n",
    "\n",
    "labels = np.concatenate(labels, axis=0)\n",
    "features = np.concatenate(features, axis=0)\n",
    "features = features[:, ::2, :, :]\n",
    "features[:, :, :, :2] = processing_data(features[:, :, :, :2])\n",
    "x_train = features\n",
    "y_train = labels\n",
    "\n",
    "features, labels = [], []\n",
    "with open(input_dataset_test, 'rb') as f:\n",
    "    fts, lbs = pickle.load(f)\n",
    "    features.append(fts)\n",
    "    labels.append(lbs)\n",
    "del fts, lbs\n",
    "\n",
    "labels = np.concatenate(labels, axis=0)\n",
    "features = np.concatenate(features, axis=0)\n",
    "features = features[:, ::2, :, :]\n",
    "features[:, :, :, :2] = processing_data(features[:, :, :, :2])\n",
    "x_valid = features\n",
    "y_valid = labels\n",
    "\n",
    "del features, labels\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(x_train, dtype=torch.float32).permute(0, 3, 1, 2),\n",
    "                              torch.tensor(y_train, dtype=torch.float32))\n",
    "val_dataset = TensorDataset(torch.tensor(x_valid, dtype=torch.float32).permute(0, 3, 1, 2),\n",
    "                            torch.tensor(y_valid, dtype=torch.float32))\n",
    "\n",
    "del x_train, x_valid, y_train, y_valid\n",
    "\n",
    "# create folder save\n",
    "if not os.path.exists(path_save_model):\n",
    "    os.mkdir(path_save_model)\n",
    "count = 0\n",
    "while os.path.exists(path_save_model + f'/exp{count}'):\n",
    "    count += 1\n",
    "path_save_model = path_save_model + f'/exp{count}'\n",
    "os.mkdir(path_save_model)\n",
    "\n",
    "# load data loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=batch_size, pin_memory=True)\n",
    "\n",
    "del train_dataset, val_dataset\n",
    "\n",
    "def set_training(model, mode=True):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = mode\n",
    "    model.train(mode)\n",
    "    return model\n",
    "\n",
    "graph_args = {'strategy': 'spatial'}\n",
    "model = TwoStreamSpatialTemporalGraph(graph_args, len(classes_name)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "losser = torch.nn.BCELoss()\n",
    "\n",
    "def train_model(model, losser, optimizer, num_epochs):\n",
    "    best_loss_acc = -1\n",
    "    for epoch in range(num_epochs):\n",
    "        losses_train = 0.0\n",
    "        train_corrects = 0\n",
    "        model = set_training(model, True)\n",
    "        pbar_train = tqdm(train_loader, desc=f'Epoch {epoch}', unit='batch')\n",
    "        for batch_vid, labels in pbar_train:\n",
    "            mot = batch_vid[:, :2, 1:, :] - batch_vid[:, :2, :-1, :]\n",
    "            mot, batch_vid, labels = mot.to(device), batch_vid.to(device), labels.to(device)\n",
    "            outputs = model((batch_vid, mot))\n",
    "            loss = losser(outputs, labels)\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses_train += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_corrects += (preds == labels.data.argmax(1)).detach().cpu().numpy().mean()\n",
    "\n",
    "        epoch_loss = losses_train / len(train_loader)\n",
    "        epoch_acc = train_corrects / len(train_loader)\n",
    "        logging.warning(f'Train: Accuracy: {epoch_acc}, Loss: {epoch_loss}')\n",
    "\n",
    "        # Validation\n",
    "        losses_val = 0.0\n",
    "        val_corrects = 0\n",
    "        model = set_training(model, False)\n",
    "        with torch.no_grad():\n",
    "            for batch_vid, labels in val_loader:\n",
    "                mot = batch_vid[:, :2, 1:, :] - batch_vid[:, :2, :-1, :]\n",
    "                mot, batch_vid, labels = mot.to(device), batch_vid.to(device), labels.to(device)\n",
    "                outputs = model((batch_vid, mot))\n",
    "                loss = losser(outputs, labels)\n",
    "                losses_val += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_corrects += (preds == labels.data.argmax(1)).detach().cpu().numpy().mean()\n",
    "\n",
    "            epoch_loss = losses_val / len(val_loader)\n",
    "            epoch_acc = val_corrects / len(val_loader)\n",
    "            logging.warning(f'Validation: Accuracy: {epoch_acc}, Loss: {epoch_loss}')\n",
    "            if best_loss_acc == -1 or best_loss_acc <= epoch_acc:\n",
    "                best_loss_acc = epoch_acc\n",
    "                torch.save(model.state_dict(), path_save_model + '/best.pt')\n",
    "                logging.warning(f'Saved best model at epoch {epoch}')\n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    model_trained = train_model(model, losser, optimizer, num_epochs=epochs)\n",
    "    torch.save(model_trained.state_dict(), path_save_model + '/last.pt')\n",
    "    logging.warning(f'Saved last model at {path_save_model}/last.pt')\n",
    "    print(\"Complete !\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c68a93a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-21T07:46:27.929694Z",
     "iopub.status.busy": "2025-03-21T07:46:27.929102Z",
     "iopub.status.idle": "2025-03-21T09:17:14.102169Z",
     "shell.execute_reply": "2025-03-21T09:17:14.101169Z"
    },
    "papermill": {
     "duration": 5452.553591,
     "end_time": "2025-03-21T09:17:18.396748",
     "exception": false,
     "start_time": "2025-03-21T07:46:25.843157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class name: ['Fall Down', 'Lying Down', 'Sit down', 'Sitting', 'Stand up', 'Standing', 'Walking']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 887/887 [01:40<00:00,  8.84batch/s]\n",
      "Epoch 1: 100%|██████████| 887/887 [01:40<00:00,  8.87batch/s]\n",
      "Epoch 2: 100%|██████████| 887/887 [01:39<00:00,  8.88batch/s]\n",
      "Epoch 3: 100%|██████████| 887/887 [01:40<00:00,  8.81batch/s]\n",
      "Epoch 4: 100%|██████████| 887/887 [01:40<00:00,  8.81batch/s]\n",
      "Epoch 5: 100%|██████████| 887/887 [01:40<00:00,  8.83batch/s]\n",
      "Epoch 6: 100%|██████████| 887/887 [01:40<00:00,  8.82batch/s]\n",
      "Epoch 7: 100%|██████████| 887/887 [01:40<00:00,  8.85batch/s]\n",
      "Epoch 8: 100%|██████████| 887/887 [01:40<00:00,  8.83batch/s]\n",
      "Epoch 9: 100%|██████████| 887/887 [01:40<00:00,  8.84batch/s]\n",
      "Epoch 10: 100%|██████████| 887/887 [01:39<00:00,  8.87batch/s]\n",
      "Epoch 11: 100%|██████████| 887/887 [01:39<00:00,  8.87batch/s]\n",
      "Epoch 12: 100%|██████████| 887/887 [01:39<00:00,  8.88batch/s]\n",
      "Epoch 13: 100%|██████████| 887/887 [01:40<00:00,  8.84batch/s]\n",
      "Epoch 14: 100%|██████████| 887/887 [01:39<00:00,  8.88batch/s]\n",
      "Epoch 15: 100%|██████████| 887/887 [01:40<00:00,  8.87batch/s]\n",
      "Epoch 16: 100%|██████████| 887/887 [01:40<00:00,  8.86batch/s]\n",
      "Epoch 17: 100%|██████████| 887/887 [01:40<00:00,  8.85batch/s]\n",
      "Epoch 18: 100%|██████████| 887/887 [01:39<00:00,  8.88batch/s]\n",
      "Epoch 19: 100%|██████████| 887/887 [01:40<00:00,  8.86batch/s]\n",
      "Epoch 20: 100%|██████████| 887/887 [01:40<00:00,  8.86batch/s]\n",
      "Epoch 21: 100%|██████████| 887/887 [01:40<00:00,  8.84batch/s]\n",
      "Epoch 22: 100%|██████████| 887/887 [01:39<00:00,  8.88batch/s]\n",
      "Epoch 23: 100%|██████████| 887/887 [01:39<00:00,  8.88batch/s]\n",
      "Epoch 24: 100%|██████████| 887/887 [01:39<00:00,  8.88batch/s]\n",
      "Epoch 25: 100%|██████████| 887/887 [01:39<00:00,  8.88batch/s]\n",
      "Epoch 26: 100%|██████████| 887/887 [01:40<00:00,  8.84batch/s]\n",
      "Epoch 27: 100%|██████████| 887/887 [01:40<00:00,  8.84batch/s]\n",
      "Epoch 28: 100%|██████████| 887/887 [01:40<00:00,  8.84batch/s]\n",
      "Epoch 29: 100%|██████████| 887/887 [01:40<00:00,  8.84batch/s]\n",
      "Epoch 30: 100%|██████████| 887/887 [01:40<00:00,  8.84batch/s]\n",
      "Epoch 31: 100%|██████████| 887/887 [01:40<00:00,  8.84batch/s]\n",
      "Epoch 32: 100%|██████████| 887/887 [01:40<00:00,  8.83batch/s]\n",
      "Epoch 33: 100%|██████████| 887/887 [01:40<00:00,  8.84batch/s]\n",
      "Epoch 34: 100%|██████████| 887/887 [01:40<00:00,  8.82batch/s]\n",
      "Epoch 35: 100%|██████████| 887/887 [01:40<00:00,  8.83batch/s]\n",
      "Epoch 36: 100%|██████████| 887/887 [01:40<00:00,  8.83batch/s]\n",
      "Epoch 37: 100%|██████████| 887/887 [01:40<00:00,  8.82batch/s]\n",
      "Epoch 38: 100%|██████████| 887/887 [01:40<00:00,  8.84batch/s]\n",
      "Epoch 39: 100%|██████████| 887/887 [01:40<00:00,  8.84batch/s]\n",
      "Epoch 40: 100%|██████████| 887/887 [01:40<00:00,  8.85batch/s]\n",
      "Epoch 41: 100%|██████████| 887/887 [01:40<00:00,  8.84batch/s]\n",
      "Epoch 42: 100%|██████████| 887/887 [01:40<00:00,  8.83batch/s]\n",
      "Epoch 43: 100%|██████████| 887/887 [01:40<00:00,  8.84batch/s]\n",
      "Epoch 44: 100%|██████████| 887/887 [01:40<00:00,  8.83batch/s]\n",
      "Epoch 45: 100%|██████████| 887/887 [01:40<00:00,  8.84batch/s]\n",
      "Epoch 46: 100%|██████████| 887/887 [01:40<00:00,  8.84batch/s]\n",
      "Epoch 47: 100%|██████████| 887/887 [01:40<00:00,  8.85batch/s]\n",
      "Epoch 48: 100%|██████████| 887/887 [01:40<00:00,  8.83batch/s]\n",
      "Epoch 49: 100%|██████████| 887/887 [01:40<00:00,  8.84batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete !\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from tqdm import tqdm\n",
    "from torch.utils import data\n",
    "from torch.optim.adadelta import Adadelta\n",
    "import sys\n",
    "sys.path.append('/kaggle/working/ST-GCN-Pytorch')\n",
    "from models.stgcn import *\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from collections import OrderedDict\n",
    "import logging\n",
    "import yaml\n",
    "from dataloader.dataset import processing_data\n",
    "import datetime\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# clear memory cuda\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "# Get parameter\n",
    "with open(\"/kaggle/input/yaml-action-pkl/config.yaml\", \"r\") as stream:\n",
    "    try:\n",
    "        config = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(\"Error loading YAML:\", exc)\n",
    "        config = {}\n",
    "\n",
    "# parameter\n",
    "input_dataset_train = config.get('dataset-path-train', '')\n",
    "input_dataset_test = config.get('dataset-path-test', '')\n",
    "epochs = config.get('epochs', 50)\n",
    "batch_size = config.get('batch-size', 32)\n",
    "input_size = config.get('img-size', 224)\n",
    "num_frame = config.get('num-frame', 15)\n",
    "path_save_model = config.get('project', 'saved_models')\n",
    "classes_name = config.get('classes', ['Fall Down', 'Lying Down', 'Sit down', 'Sitting', 'Stand up', 'Standing', 'Walking'])\n",
    "\n",
    "print(\"Class name:\", classes_name)\n",
    "\n",
    "features, labels = [], []\n",
    "# Load dataset train\n",
    "with open(input_dataset_train, 'rb') as f:\n",
    "    fts, lbs = pickle.load(f)\n",
    "    features.append(fts)\n",
    "    labels.append(lbs)\n",
    "del fts, lbs\n",
    "\n",
    "# Normalize class\n",
    "labels = np.concatenate(labels, axis=0)\n",
    "features = np.concatenate(features, axis=0)\n",
    "features = features[:, ::2, :, :]\n",
    "features[:, :, :, :2] = processing_data(features[:, :, :, :2])\n",
    "x_train = features\n",
    "y_train = labels\n",
    "\n",
    "features, labels = [], []\n",
    "with open(input_dataset_test, 'rb') as f:\n",
    "    fts, lbs = pickle.load(f)\n",
    "    features.append(fts)\n",
    "    labels.append(lbs)\n",
    "del fts, lbs\n",
    "\n",
    "labels = np.concatenate(labels, axis=0)\n",
    "features = np.concatenate(features, axis=0)\n",
    "features = features[:, ::2, :, :]\n",
    "features[:, :, :, :2] = processing_data(features[:, :, :, :2])\n",
    "x_valid = features\n",
    "y_valid = labels\n",
    "\n",
    "del features, labels\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(x_train, dtype=torch.float32).permute(0, 3, 1, 2),\n",
    "                              torch.tensor(y_train, dtype=torch.float32))\n",
    "val_dataset = TensorDataset(torch.tensor(x_valid, dtype=torch.float32).permute(0, 3, 1, 2),\n",
    "                            torch.tensor(y_valid, dtype=torch.float32))\n",
    "\n",
    "del x_train, x_valid, y_train, y_valid\n",
    "\n",
    "# create folder save\n",
    "if not os.path.exists(path_save_model):\n",
    "    os.mkdir(path_save_model)\n",
    "count = 0\n",
    "while os.path.exists(path_save_model + f'/exp{count}'):\n",
    "    count += 1\n",
    "path_save_model = path_save_model + f'/exp{count}'\n",
    "os.mkdir(path_save_model)\n",
    "\n",
    "# load data loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=batch_size, pin_memory=True)\n",
    "\n",
    "del train_dataset, val_dataset\n",
    "\n",
    "graph_args = {'strategy': 'spatial'}\n",
    "model = TwoStreamSpatialTemporalGraph(graph_args, len(classes_name)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "losser = torch.nn.BCELoss()\n",
    "\n",
    "def main():\n",
    "    model_trained = train_model(model, losser, optimizer, num_epochs=epochs)\n",
    "    torch.save(model_trained.state_dict(), path_save_model + '/last.pt')\n",
    "    logging.warning('Saved last model at {}'.format(path_save_model))\n",
    "    print(\"Complete !\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6928034,
     "sourceId": 11112100,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6928112,
     "sourceId": 11112215,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6918835,
     "sourceId": 11099103,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10941.293791,
   "end_time": "2025-03-21T09:17:25.154814",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-21T06:15:03.861023",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
